from __future__ import annotations
import numpy as np
import cv2

from config.settings import settings
from pipeline.models import load_insightface_app

def l2_normalize(vec: np.ndarray, eps: float = 1e-10) -> np.ndarray:
    n = np.linalg.norm(vec)
    if n < eps:
        return vec
    return vec / n

def embed(aligned_bgr_112: "np.ndarray") -> "np.ndarray":
    """
    Generate embedding from an aligned 112x112 BGR face crop.
    
    CRITICAL: This uses the EXACT same preprocessing as InsightFace's internal
    ArcFaceONNX.get_feat() method to ensure embeddings are compatible with
    embeddings generated by app.get() (used by GPU worker/crawler).
    
    The key is using cv2.dnn.blobFromImages with swapRB=True which:
    1. Swaps BGR -> RGB (InsightFace recognition models expect RGB)
    2. Normalizes with (img - mean) / std
    3. Transposes HWC -> CHW
    
    Args:
        aligned_bgr_112: ndarray HxWxC, 112x112x3, BGR aligned crop
        
    Returns:
        np.ndarray shape (512,), dtype float32, L2-normalized
    """
    app = load_insightface_app()

    if aligned_bgr_112 is None or aligned_bgr_112.ndim != 3 or aligned_bgr_112.shape[:2] != (settings.IMAGE_SIZE, settings.IMAGE_SIZE):
        raise ValueError(f"Expected aligned {settings.IMAGE_SIZE}x{settings.IMAGE_SIZE} BGR image, got {None if aligned_bgr_112 is None else aligned_bgr_112.shape}")

    # Ensure uint8 for cv2.dnn.blobFromImages
    if aligned_bgr_112.dtype != np.uint8:
        img = np.clip(aligned_bgr_112, 0, 255).astype(np.uint8)
    else:
        img = aligned_bgr_112

    rec_model = app.models['recognition']
    
    # Use EXACT same preprocessing as InsightFace's ArcFaceONNX.get_feat()
    # This ensures embeddings match those from app.get() used by GPU worker
    # 
    # InsightFace source (recognition_arcface.py):
    #   blob = cv2.dnn.blobFromImages([aimg], 1.0/input_std, input_size, 
    #                                  (input_mean, input_mean, input_mean), swapRB=True)
    #
    # input_mean = 127.5, input_std = 127.5 for buffalo_l/w600k_r50.onnx
    input_mean = 127.5
    input_std = 127.5
    
    blob = cv2.dnn.blobFromImages(
        [img], 
        1.0 / input_std,  # Scale factor
        (112, 112),       # Size
        (input_mean, input_mean, input_mean),  # Mean subtraction
        swapRB=True       # BGR -> RGB (CRITICAL for matching GPU worker embeddings!)
    )
    
    # Run through recognition model
    feat = rec_model.session.run(rec_model.output_names, {rec_model.input_name: blob})[0][0]
    feat = feat.astype(np.float32, copy=False)
    feat = l2_normalize(feat).astype(np.float32, copy=False)
    
    if feat.shape[0] != 512:
        raise ValueError(f"Expected 512-dim embedding, got {feat.shape}")
    return feat