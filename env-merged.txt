# Mordeaux Face Scanning MVP - Environment Configuration
# Merged from main branch and GPU worker branch
# Copy this file to .env and configure your values

# ============================================================================
# Environment & Deployment
# ============================================================================
ENVIRONMENT=development
TZ=America/Los_Angeles
LOG_LEVEL=info
LOG_FORMAT=json

# ============================================================================
# Database Configuration
# ============================================================================
POSTGRES_DB=mordeaux
POSTGRES_USER=mordeaux
POSTGRES_PASSWORD=mordeaux123

# ============================================================================
# Storage Configuration (MinIO/S3)
# ============================================================================
S3_ENDPOINT=http://minio:9000
S3_REGION=us-east-1
S3_BUCKET_RAW=raw-images
S3_BUCKET_THUMBS=thumbnails
S3_BUCKET_AUDIT=audit-logs
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_USE_SSL=false
S3_PUBLIC_ENDPOINT=

# ============================================================================
# Vector Database Configuration
# ============================================================================
VECTOR_INDEX=faces_v1

# Qdrant (local)
QDRANT_URL=http://qdrant:6333
DEFAULT_SEARCH_TOPK=10
MAX_SEARCH_TOPK=100

# Pinecone (production)
PINECONE_API_KEY=
PINECONE_INDEX=faces_v1

# ============================================================================
# Redis Configuration
# ============================================================================
REDIS_URL=redis://redis:6379/0
CELERY_BROKER_URL=redis://redis:6379/1
CELERY_RESULT_BACKEND=redis://redis:6379/2

# ============================================================================
# Application Configuration
# ============================================================================
ASGI_WORKERS=2
NGINX_MAX_BODY=50m

# ============================================================================
# Frontend Configuration
# ============================================================================
VITE_API_BASE=/api

# ============================================================================
# API Configuration
# ============================================================================
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4
API_RELOAD=false
CORS_ORIGINS=*

# ============================================================================
# Logging & Monitoring
# ============================================================================
ENABLE_METRICS=true
METRICS_PORT=9090

# ============================================================================
# Face Processing Configuration
# ============================================================================
# Face Detection & Embedding Settings
DETECTOR_MODEL=buffalo_l
DETECTOR_CTX_ID=-1  # -1 for CPU, 0+ for GPU
DETECTOR_SIZE_WIDTH=640
DETECTOR_SIZE_HEIGHT=640
EMBEDDING_DIM=512
NORMALIZE_EMBEDDINGS=true

# Quality Thresholds
MIN_FACE_QUALITY=0.5
MIN_FACE_SIZE=50
MAX_BLUR_SCORE=100.0
MIN_SHARPNESS=100.0
MIN_BRIGHTNESS=30.0
MAX_BRIGHTNESS=225.0
MAX_POSE_ANGLE=45.0
MIN_OVERALL_QUALITY=0.7

# Legacy Face Detection Settings (for backward compatibility)
FACE_MODEL_NAME=buffalo_l
FACE_DETECTION_SIZE_WIDTH=1024
FACE_DETECTION_SIZE_HEIGHT=1024
MIN_FACE_DETECTION_SCORE=0.6
MIN_FACE_QUALITY_SCORE=0.5
MIN_SIMILARITY_THRESHOLD=0.4
MIN_CONFIDENCE_THRESHOLD=0.4

# Pipeline Configuration
MAX_FACES_PER_IMAGE=10
BATCH_SIZE=32
MAX_CONCURRENT_TASKS=5
ENABLE_DEDUPLICATION=true

# Face Alignment
ENABLE_FACE_ALIGNMENT=true

# Model Ensemble
ENABLE_MODEL_ENSEMBLE=false
ENSEMBLE_MODELS=buffalo_l,buffalo_m,buffalo_s
ENSEMBLE_FUSION_STRATEGY=weighted_avg

# ============================================================================
# GPU Configuration - DirectML for AMD GPU
# ============================================================================
# The GPU worker should run natively on Windows (outside Docker) for GPU access
# Docker containers access it via host.docker.internal:8765
# To change the endpoint, update GPU_WORKER_URL in config.py
GPU_TYPE=directml
GPU_BACKEND=directml
ALL_GPU=false
FACE_DETECTION_GPU=true
FACE_EMBEDDING_GPU=true
IMAGE_PROCESSING_GPU=false
IMAGE_ENHANCEMENT_GPU=false
QUALITY_CHECKS_GPU=false
GPU_DEVICE_ID=0
GPU_MEMORY_LIMIT_GB=8
GPU_BATCH_SIZE=128

# GPU Worker Configuration
GPU_WORKER_ENABLED=true
GPU_WORKER_URL=http://host.docker.internal:8765
GPU_WORKER_TIMEOUT=60.0
GPU_WORKER_MAX_RETRIES=3

# DirectML Environment Variables (set automatically by ONNX Runtime)

# ============================================================================
# Dynamic Resource Management - AGGRESSIVE INTERVALS
# ============================================================================
ENABLE_DYNAMIC_RESOURCES=true
ADJUSTMENT_INTERVAL_S=0.3
TARGET_CPU_UTILIZATION=90.0
TARGET_GPU_UTILIZATION=92.0
TARGET_MEMORY_UTILIZATION=75.0

# Concurrency Bounds - HIGH THROUGHPUT
MIN_CONCURRENT_DOWNLOADS=20
MAX_CONCURRENT_DOWNLOADS=200
MIN_BATCH_SIZE=10
MAX_BATCH_SIZE=256
MIN_CONCURRENT_SITES=5
MAX_CONCURRENT_SITES=30

# Adjustment Behavior - MODERATE STEPS, FAST INTERVALS
AGGRESSIVE_SCALING=false
SMOOTHING_FACTOR=0.3
ADJUSTMENT_STEP_SIZE=5
ADJUSTMENT_STEP_SIZE_DECREMENT=2
ADJUSTMENT_STEP_PERCENT=10.0
ADJUSTMENT_STEP_PERCENT_DECREMENT=5.0
UTILIZATION_DEADBAND=3.0
WARMUP_PERIOD_S=5.0
MAX_ADJUSTMENT_PER_MINUTE=100

