#!/usr/bin/env python3
"""
review-selectors - CLI tool for reviewing and approving image selectors

Usage:
    review-selectors --domain example.com [--yaml site_recipes.yaml] [--download-dir /tmp/review]

This tool downloads sample thumbnails for each candidate selector,
displays them in a console interface for review, and updates the YAML
file based on user approval.
"""

import argparse
import asyncio
import logging
import os
import sys
import tempfile
from pathlib import Path
from typing import List, Dict, Optional

# Add the project root to the path
sys.path.append(str(Path(__file__).parent.parent))

from tools.selector_miner import SelectorMiner
import httpx
import yaml


def setup_logging(verbose: bool = False):
    """Set up logging configuration."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%H:%M:%S'
    )


def load_domain_recipe(domain: str, yaml_file: str) -> Optional[Dict]:
    """
    Load recipe for a domain from YAML file.
    
    Args:
        domain: Domain name to load
        yaml_file: Path to YAML file
        
    Returns:
        Recipe dictionary if found, None otherwise
    """
    yaml_path = Path(yaml_file)
    if not yaml_path.exists():
        logging.error(f"YAML file not found: {yaml_file}")
        return None
    
    try:
        with open(yaml_path, 'r', encoding='utf-8') as f:
            recipes = yaml.safe_load(f) or {}
        
        sites = recipes.get('sites', {})
        if domain not in sites:
            logging.error(f"No recipe found for domain: {domain}")
            return None
        
        recipe = sites[domain]
        recipe['domain'] = domain
        return recipe
        
    except Exception as e:
        logging.error(f"Error loading YAML file: {e}")
        return None


async def download_sample_images(selectors: List[Dict], domain: str, download_dir: str, max_per_selector: int = 6) -> Dict[str, List[str]]:
    """
    Download sample images for each selector.
    
    Args:
        selectors: List of selector dictionaries
        domain: Domain name
        download_dir: Directory to download images to
        max_per_selector: Maximum images to download per selector
        
    Returns:
        Dictionary mapping selector to list of downloaded image paths
    """
    downloaded_images = {}
    download_path = Path(download_dir)
    download_path.mkdir(parents=True, exist_ok=True)
    
    async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
        for i, selector in enumerate(selectors):
            selector_key = selector['selector']
            logging.info(f"Downloading samples for selector {i+1}/{len(selectors)}: {selector_key}")
            
            # Create a directory for this selector
            selector_dir = download_path / f"selector_{i+1}"
            selector_dir.mkdir(exist_ok=True)
            
            downloaded_paths = []
            
            # For demo purposes, we'll generate some sample image URLs
            # In a real implementation, you would use the actual URLs from the selector
            sample_urls = [
                f"https://{domain}/sample1.jpg",
                f"https://{domain}/sample2.jpg", 
                f"https://{domain}/sample3.jpg",
                f"https://{domain}/sample4.jpg",
                f"https://{domain}/sample5.jpg",
                f"https://{domain}/sample6.jpg"
            ]
            
            for j, url in enumerate(sample_urls[:max_per_selector]):
                try:
                    # Try to download the image
                    response = await client.get(url)
                    
                    if response.status_code == 200:
                        content_type = response.headers.get('content-type', '').lower()
                        if 'image/' in content_type:
                            # Save the image
                            ext = content_type.split('/')[-1]
                            if ext not in ['jpeg', 'jpg', 'png', 'gif', 'webp']:
                                ext = 'jpg'
                            
                            image_path = selector_dir / f"sample_{j+1}.{ext}"
                            with open(image_path, 'wb') as f:
                                f.write(response.content)
                            
                            downloaded_paths.append(str(image_path))
                            logging.debug(f"Downloaded: {image_path}")
                        else:
                            logging.warning(f"Non-image content from {url}: {content_type}")
                    else:
                        logging.warning(f"Failed to download {url}: HTTP {response.status_code}")
                        
                except Exception as e:
                    logging.warning(f"Error downloading {url}: {e}")
            
            downloaded_images[selector_key] = downloaded_paths
            logging.info(f"Downloaded {len(downloaded_paths)} images for selector: {selector_key}")
    
    return downloaded_images


def display_review_interface(selectors: List[Dict], downloaded_images: Dict[str, List[str]]) -> List[bool]:
    """
    Display console interface for reviewing selectors.
    
    Args:
        selectors: List of selector dictionaries
        downloaded_images: Dictionary mapping selectors to downloaded image paths
        
    Returns:
        List of boolean values indicating approval for each selector
    """
    approvals = []
    
    print("\n" + "="*80)
    print("SELECTOR REVIEW INTERFACE")
    print("="*80)
    print("Review each selector and approve (y) or reject (n)")
    print("Press Enter for default (approve)")
    print("="*80)
    
    for i, selector in enumerate(selectors):
        selector_key = selector['selector']
        description = selector.get('description', 'No description')
        image_paths = downloaded_images.get(selector_key, [])
        
        print(f"\n[{i+1}/{len(selectors)}] SELECTOR REVIEW")
        print("-" * 60)
        print(f"Selector: {selector_key}")
        print(f"Description: {description}")
        print(f"Downloaded Images: {len(image_paths)}")
        
        if image_paths:
            print("Sample Images:")
            for j, image_path in enumerate(image_paths[:4]):  # Show max 4
                print(f"  {j+1}. {image_path}")
            if len(image_paths) > 4:
                print(f"  ... and {len(image_paths) - 4} more")
        else:
            print("  ⚠️  No images were successfully downloaded")
        
        # Get user input
        while True:
            try:
                response = input(f"\nApprove this selector? [Y/n]: ").strip().lower()
                if response in ['', 'y', 'yes']:
                    approvals.append(True)
                    print("✅ APPROVED")
                    break
                elif response in ['n', 'no']:
                    approvals.append(False)
                    print("❌ REJECTED")
                    break
                else:
                    print("Please enter 'y' for yes or 'n' for no")
            except KeyboardInterrupt:
                print("\n\nReview cancelled by user")
                return []
    
    return approvals


def update_yaml_with_approvals(domain: str, selectors: List[Dict], approvals: List[bool], yaml_file: str) -> bool:
    """
    Update YAML file based on approval decisions.
    
    Args:
        domain: Domain name
        selectors: List of selector dictionaries
        approvals: List of approval decisions
        yaml_file: Path to YAML file
        
    Returns:
        True if successful, False otherwise
    """
    try:
        # Load existing recipes
        yaml_path = Path(yaml_file)
        with open(yaml_path, 'r', encoding='utf-8') as f:
            recipes = yaml.safe_load(f) or {}
        
        # Filter selectors based on approvals
        approved_selectors = [
            selector for selector, approved in zip(selectors, approvals)
            if approved
        ]
        
        # Update the recipe
        if 'sites' not in recipes:
            recipes['sites'] = {}
        
        if domain in recipes['sites']:
            recipes['sites'][domain]['selectors'] = approved_selectors
        else:
            logging.warning(f"Domain {domain} not found in YAML file")
            return False
        
        # Write back to file
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(recipes, f, default_flow_style=False, sort_keys=False)
        
        logging.info(f"Updated YAML file with {len(approved_selectors)} approved selectors")
        return True
        
    except Exception as e:
        logging.error(f"Failed to update YAML file: {e}")
        return False


def cleanup_download_dir(download_dir: str):
    """Clean up the download directory."""
    try:
        import shutil
        if Path(download_dir).exists():
            shutil.rmtree(download_dir)
            logging.info(f"Cleaned up download directory: {download_dir}")
    except Exception as e:
        logging.warning(f"Failed to clean up download directory: {e}")


async def main():
    """Main CLI function."""
    parser = argparse.ArgumentParser(
        description="Review and approve image selectors for a domain",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  review-selectors --domain example.com
  review-selectors --domain example.com --yaml site_recipes.yaml --download-dir /tmp/review
  review-selectors --domain example.com --verbose
        """
    )
    
    parser.add_argument('--domain', required=True, help='Domain name to review')
    parser.add_argument('--yaml', default='site_recipes.yaml', help='YAML file path (default: site_recipes.yaml)')
    parser.add_argument('--download-dir', help='Directory to download sample images (default: temporary directory)')
    parser.add_argument('--keep-downloads', action='store_true', help='Keep downloaded images after review')
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose logging')
    
    args = parser.parse_args()
    
    # Set up logging
    setup_logging(args.verbose)
    
    # Set up download directory
    if args.download_dir:
        download_dir = args.download_dir
    else:
        temp_dir = tempfile.mkdtemp(prefix='selector_review_')
        download_dir = temp_dir
        logging.info(f"Using temporary directory: {download_dir}")
    
    try:
        # Load domain recipe
        recipe = load_domain_recipe(args.domain, args.yaml)
        if not recipe:
            logging.error(f"No recipe found for domain: {args.domain}")
            sys.exit(1)
        
        selectors = recipe.get('selectors', [])
        if not selectors:
            logging.error(f"No selectors found for domain: {args.domain}")
            sys.exit(1)
        
        logging.info(f"Found {len(selectors)} selectors for domain: {args.domain}")
        
        # Download sample images
        logging.info("Downloading sample images...")
        downloaded_images = await download_sample_images(selectors, args.domain, download_dir)
        
        # Display review interface
        approvals = display_review_interface(selectors, downloaded_images)
        
        if not approvals:
            logging.info("Review cancelled by user")
            sys.exit(0)
        
        # Update YAML file
        success = update_yaml_with_approvals(args.domain, selectors, approvals, args.yaml)
        
        if success:
            approved_count = sum(approvals)
            total_count = len(approvals)
            logging.info(f"✅ Review completed successfully!")
            print(f"\nApproved {approved_count}/{total_count} selectors for {args.domain}")
            print(f"Updated {args.yaml}")
        else:
            logging.error("Failed to update YAML file")
            sys.exit(1)
            
    except KeyboardInterrupt:
        logging.info("Review cancelled by user")
        sys.exit(0)
    except Exception as e:
        logging.error(f"Unexpected error: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    finally:
        # Clean up download directory unless keeping downloads
        if not args.keep_downloads:
            cleanup_download_dir(download_dir)


if __name__ == "__main__":
    asyncio.run(main())
