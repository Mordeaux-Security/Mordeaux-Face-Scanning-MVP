#!/usr/bin/env python3
"""
mine-selectors - CLI tool for mining and validating image selectors

Usage:
    mine-selectors --domain example.com --urls urls.txt --out site_recipes.yaml [--append]

This tool analyzes HTML content from URLs, mines candidate selectors,
validates them, and merges successful recipes into the site_recipes.yaml file.
"""

import argparse
import asyncio
import logging
import sys
from pathlib import Path
from typing import List, Optional

# Add the project root to the path
sys.path.append(str(Path(__file__).parent.parent))

from tools.selector_miner import SelectorMiner, propose_recipe_for_domain
from tools.redirect_utils import create_safe_client, fetch_html_with_redirects
import httpx


def setup_logging(verbose: bool = False):
    """Set up logging configuration."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%H:%M:%S'
    )


def parse_urls_file(urls_file: str) -> List[str]:
    """
    Parse URLs from a text file.
    
    Args:
        urls_file: Path to file containing URLs (one per line)
        
    Returns:
        List of URLs
        
    Raises:
        FileNotFoundError: If the file doesn't exist
        ValueError: If no valid URLs are found
    """
    urls_path = Path(urls_file)
    if not urls_path.exists():
        raise FileNotFoundError(f"URLs file not found: {urls_file}")
    
    urls = []
    with open(urls_path, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            url = line.strip()
            if url and not url.startswith('#'):  # Skip empty lines and comments
                urls.append(url)
    
    if not urls:
        raise ValueError(f"No valid URLs found in {urls_file}")
    
    logging.info(f"Loaded {len(urls)} URLs from {urls_file}")
    return urls


async def fetch_html_content(urls: List[str], max_urls: int = 3) -> Optional[str]:
    """
    Fetch HTML content from the first few URLs.
    
    Args:
        urls: List of URLs to try
        max_urls: Maximum number of URLs to try
        
    Returns:
        HTML content from the first successful fetch, or None if all fail
    """
    async with create_safe_client(timeout=30.0) as client:
        for i, url in enumerate(urls[:max_urls]):
            try:
                logging.info(f"Fetching HTML from: {url}")
                html_content, reason = await fetch_html_with_redirects(url, client, max_hops=3)
                
                if html_content is not None:
                    logging.info(f"Successfully fetched HTML from {url} ({len(html_content)} chars)")
                    return html_content
                else:
                    logging.warning(f"Failed to fetch {url}: {reason}")
                    
            except Exception as e:
                logging.warning(f"Error fetching {url}: {e}")
    
    return None


async def mine_selectors_for_domain(domain: str, urls: List[str], verbose: bool = False, js_fallback: bool = False, min_candidates: int = 3, max_bytes: Optional[int] = None) -> Optional[dict]:
    """
    Mine selectors for a domain from the provided URLs.
    
    Args:
        domain: Domain name to analyze
        urls: List of URLs to fetch HTML from
        verbose: Enable verbose logging
        js_fallback: Enable JavaScript fallback for dynamic content
        min_candidates: Minimum candidates before JS fallback
        max_bytes: Maximum image size in bytes
        
    Returns:
        Recipe dictionary if successful, None otherwise
    """
    logging.info(f"Starting selector mining for domain: {domain}")
    
    # Fetch HTML content
    html_content = await fetch_html_content(urls)
    if not html_content:
        logging.error("Failed to fetch HTML content from any URL")
        return None
    
    # Propose recipe
    try:
        if js_fallback:
            # Use JS fallback if enabled
            from tools.selector_miner import mine_selectors_with_js_fallback, propose_recipe
            
            logging.info("Using JavaScript fallback for selector mining")
            candidates = await mine_selectors_with_js_fallback(
                html_content, 
                urls[0] if urls else f"https://{domain}", 
                f"https://{domain}",
                min_candidates,
                max_bytes
            )
            
            if not candidates:
                logging.error("No selectors found even with JavaScript fallback")
                return None
            
            # Create miner instance for recipe proposal
            from tools.selector_miner import SelectorMiner
            miner = SelectorMiner(f"https://{domain}", max_bytes=max_bytes)
            miner.mine_selectors(html_content)  # Set up the miner state
            recipe = await miner.propose_recipe(domain, html_content)
        else:
            # Use standard static mining
            recipe = await propose_recipe_for_domain(domain, html_content, f"https://{domain}", max_bytes)
        
        if not recipe:
            logging.error("No recipe could be proposed - validation failed or no suitable selectors found")
            return None
        
        logging.info(f"Recipe proposed with confidence: {recipe.confidence:.3f}")
        logging.info(f"Found {len(recipe.selectors)} selectors")
        logging.info(f"Attributes priority: {recipe.attributes_priority}")
        logging.info(f"Extra sources: {recipe.extra_sources}")
        
        if verbose:
            logging.info("Top selectors:")
            for i, selector in enumerate(recipe.selectors[:3], 1):
                logging.info(f"  {i}. {selector['selector']} - {selector['description']}")
        
        # Convert to dictionary format
        recipe_dict = {
            'domain': recipe.domain,
            'selectors': recipe.selectors,
            'attributes_priority': recipe.attributes_priority,
            'extra_sources': recipe.extra_sources,
            'method': recipe.method,
            'confidence': recipe.confidence,
            'sample_urls': recipe.sample_urls
        }
        
        return recipe_dict
        
    except Exception as e:
        logging.error(f"Error proposing recipe: {e}")
        return None


def merge_recipe_to_yaml(recipe_dict: dict, yaml_file: str, append: bool = True) -> bool:
    """
    Merge recipe into YAML file.
    
    Args:
        recipe_dict: Recipe dictionary to merge
        yaml_file: Path to YAML file
        append: If True, append to existing file; if False, create new file
        
    Returns:
        True if successful, False otherwise
    """
    try:
        import yaml
        
        # Load existing recipes if append is True and file exists
        existing_recipes = {'defaults': {}, 'sites': {}}
        yaml_path = Path(yaml_file)
        
        if append and yaml_path.exists():
            with open(yaml_path, 'r', encoding='utf-8') as f:
                existing_recipes = yaml.safe_load(f) or existing_recipes
        
        # Ensure required sections exist
        if 'sites' not in existing_recipes:
            existing_recipes['sites'] = {}
        
        # Add the recipe
        existing_recipes['sites'][recipe_dict['domain']] = {
            'selectors': recipe_dict['selectors'],
            'attributes_priority': recipe_dict['attributes_priority'],
            'extra_sources': recipe_dict['extra_sources'],
            'method': recipe_dict['method']
        }
        
        # Write back to file
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(existing_recipes, f, default_flow_style=False, sort_keys=False)
        
        logging.info(f"Successfully merged recipe for {recipe_dict['domain']} into {yaml_file}")
        return True
        
    except Exception as e:
        logging.error(f"Failed to merge recipe: {e}")
        return False


async def main():
    """Main CLI function."""
    parser = argparse.ArgumentParser(
        description="Mine and validate image selectors for a domain",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  mine-selectors --domain example.com --urls urls.txt --out site_recipes.yaml
  mine-selectors --domain example.com --urls urls.txt --out site_recipes.yaml --append --verbose
  mine-selectors --domain example.com --urls urls.txt --out site_recipes.yaml --js --min-candidates 2
        """
    )
    
    parser.add_argument('--domain', required=True, help='Domain name to analyze')
    parser.add_argument('--urls', required=True, help='File containing URLs (one per line)')
    parser.add_argument('--out', required=True, help='Output YAML file path')
    parser.add_argument('--append', action='store_true', help='Append to existing YAML file (default: True)')
    parser.add_argument('--js', action='store_true', help='Enable JavaScript fallback for dynamic content (requires Playwright)')
    parser.add_argument('--min-candidates', type=int, default=3, help='Minimum candidates before JS fallback (default: 3)')
    parser.add_argument('--max-bytes', type=int, help='Maximum image size in bytes (overrides MINER_MAX_IMAGE_BYTES env var)')
    parser.add_argument('--verbose', '-v', action='store_true', help='Enable verbose logging')
    
    args = parser.parse_args()
    
    # Set up logging
    setup_logging(args.verbose)
    
    try:
        # Parse URLs
        urls = parse_urls_file(args.urls)
        
        # Mine selectors
        recipe_dict = await mine_selectors_for_domain(
            args.domain, 
            urls, 
            args.verbose, 
            args.js, 
            args.min_candidates,
            args.max_bytes
        )
        
        if not recipe_dict:
            logging.error("Failed to mine selectors")
            sys.exit(1)
        
        # Merge into YAML file
        success = merge_recipe_to_yaml(recipe_dict, args.out, args.append)
        
        if success:
            logging.info("âœ… Selector mining completed successfully!")
            print(f"\nRecipe for {args.domain} has been added to {args.out}")
            print(f"Confidence: {recipe_dict['confidence']:.3f}")
            print(f"Selectors: {len(recipe_dict['selectors'])}")
        else:
            logging.error("Failed to merge recipe into YAML file")
            sys.exit(1)
            
    except FileNotFoundError as e:
        logging.error(f"File not found: {e}")
        sys.exit(1)
    except ValueError as e:
        logging.error(f"Invalid input: {e}")
        sys.exit(1)
    except Exception as e:
        logging.error(f"Unexpected error: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
